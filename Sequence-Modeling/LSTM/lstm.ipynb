{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e82805c8-789b-4163-977e-012c69e21fc9",
   "metadata": {},
   "source": [
    "- At the heart of LSTM network is the memory cell, which retains information over time.\n",
    "- It is manipulated by three type of gates:\n",
    "  - Forget gate: Decides what information to discard from the cell state.\n",
    "  - Input gate: Determines which neew information to add the cell state.\n",
    "  - The candidate itself represents what the LSTM might add to the cell state.\n",
    "  - Output gate: Controls the ouptu based on the updated cell state.\n",
    "  - The tanh function ensures that the values of the candidate cell state range between -1 and 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca8017b1-441f-424d-8359-27db0ab88fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LSTM:\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        self.input_size = input_size # Number of input features (dimensionality of each input vector)\n",
    "        self.hidden_size = hidden_size # The number of hiddden units in the LSTM (size of hidden state)\n",
    "\n",
    "        # Initialize weights and biases for forget, input, cell, and output gates\n",
    "        self.Wf = np.random.randn(hidden_size, hidden_size + input_size) # Forget gate\n",
    "        self.Wi = np.random.randn(hidden_size, hidden_size + input_size) # Input gate\n",
    "        self.WC = np.random.randn(hidden_size, hidden_size + input_size) # Cell gate\n",
    "        self.Wo = np.random.randn(hidden_size, hidden_size + input_size) # Output gate\n",
    "\n",
    "        # Biases for each gate initialized to zeros. \n",
    "        self.bf = np.zeros((hidden_size, 1))\n",
    "        self.bi = np.zeros((hidden_size, 1))\n",
    "        self.bC = np.zeros((hidden_size, 1))\n",
    "        self.bo = np.zeros((hidden_size, 1))\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def tanh(self, z):\n",
    "        return np.tanh(z)\n",
    "\n",
    "    # Calculates the next hidden state (h_t) and cell state (C_t) based on current input and prev cell state\n",
    "    # x: The current input vector at time step t \n",
    "    # h_prev : the hidden state from prev step (t-1)\n",
    "    # C_prev : the cell state froom the prev step (t-1)\n",
    "    def forward(self, x, h_prev, C_prev):\n",
    "        # Concatenate hidden state and input\n",
    "        concat = np.vstack((h_prev, x))\n",
    "\n",
    "        # Forget gate\n",
    "        # this gate controls what portion of the previous cell state should be forgotten \n",
    "        # It takes the concatenated input of (h_prev, x) nd multiplies with forgate gate weights (Wf) and adds the forget gate bias (bf)\n",
    "        f_t = self.sigmoid(np.dot(self.Wf, concat) + self.bf)\n",
    "\n",
    "        # Input gate\n",
    "        # Deternmines which gate info will be added to the cell state \n",
    "        # It applies the same operation (weights and biases, followed by sigmoid)\n",
    "        i_t = self.sigmoid(np.dot(self.Wi, concat) + self.bi)\n",
    "        C_tilda = self.tanh(np.dot(self.WC, concat) + self.bC)\n",
    "\n",
    "        # Cell state update\n",
    "        \n",
    "        C_t = f_t * C_prev + i_t * C_tilda\n",
    "\n",
    "        # Output gate\n",
    "        # determines the next hidden state by deciding which parts of the cell state to output. \n",
    "        o_t = self.sigmoid(np.dot(self.Wo, concat) + self.bo)\n",
    "\n",
    "        # Hidden state update\n",
    "        h_t = o_t * self.tanh(C_t)\n",
    "\n",
    "        return h_t, C_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10b85a50-1db7-4668-8c5a-b5455ea27fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage \n",
    "input_size = 3 # input frature size\n",
    "hidden_size = 5 # Size of the LSTM's hidden state\n",
    "lstm = LSTM(input_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1edb02c-9905-471b-b65f-2253fe22a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy input data \n",
    "x_t = np.random.randn(input_size, 1)\n",
    "h_prev = np.zeros((hidden_size, 1))\n",
    "C_prev = np.zeros((hidden_size, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca0c7a72-8900-4417-b6e9-ee699efd9695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden state:  [[-0.08083578]\n",
      " [-0.59070795]\n",
      " [ 0.37315557]\n",
      " [ 0.29706343]\n",
      " [ 0.10785178]]\n",
      "Cell state:  [[-0.64143477]\n",
      " [-0.9282291 ]\n",
      " [ 0.75818771]\n",
      " [ 0.83166596]\n",
      " [ 0.12467049]]\n"
     ]
    }
   ],
   "source": [
    "# Forward passs \n",
    "h_t, C_t = lstm.forward(x_t, h_prev, C_prev)\n",
    "\n",
    "print(\"Hidden state: \", h_t)\n",
    "print(\"Cell state: \", C_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3ff5c2-d79c-4fde-9c6d-37fa84099509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
